{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdb81d3-7162-4736-a25e-60e06f914b46",
   "metadata": {},
   "source": [
    "# Analyse et Exploration des données S7 : Régressions linéaires\n",
    "\n",
    "- Année 2025/2026\n",
    "- Jean Delpech\n",
    "- Classe : B3 IA/Data (Campus Aix-en-Provence)\n",
    "- Dernière mise à jour : janvier 2026\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Les régressions sont les modèles les plus important en analyse de données (statisitques), en data science, machine learning compris.\n",
    "\n",
    "Ce sont des modèles :\n",
    "\n",
    "* mathématiquement très simples (relation linéaire)\n",
    "* facile à interprêter\n",
    "* sobres (besoin de peu de ressources de calculs)\n",
    "* en analyse statistique, il s’agit du modèle de référence pour modéliser une relation entre une variable quantitative et une ou plusieurs variables quantitatives\n",
    "* en machine learning, la régression appartient à la famille des apprentissages supervisés\n",
    "* c’est un modèle bien connu : la méthode d’optimisation la plus courante (moindres carrés ou OLS) est connue de longue date ([Legendre](https://journals.openedition.org/bibnum/580), puis [Guauss](https://www.persee.fr/doc/rhs_0151-4105_1989_num_42_1_4132)… en astronomie) et le terme de régression a égalemenet été forgé au XIXe s. par [Galton](https://fr.wikipedia.org/wiki/Francis_Galton) dans le cadre de recherches en anthropologie physique – régression est en fait l’abréviation de « régression vers la moyenne ». \n",
    "\n",
    "Dans [un article](https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html) sur [KDnuggets](https://www.kdnuggets.com/), [Matthias Döring](https://www.linkedin.com/in/matthias-doering/) propose un [dataset recensant le nombre de publications en contion des méthodes de machine learning employées](https://www.datascienceblog.net/data-sets/ml_models_timeline.csv). \n",
    "\n",
    "Il appert de ces données que la régression linéaire – ne serait-ce que dans le domaine du machine learning − est la méthode la plus employée. Cela est d’autant plus vrai si l’on considère toutes les variantes (logistique, Poisson, Cox, ridge, lasso…). Seule les SVM (une méthode très efficace dans le domaine de la classification) pourrait rivaliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b5e77-dca1-4947-8d39-a2d7c6bad3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae60826-1e0b-4603-803a-d1910b27c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_timeline = pd.read_csv('data/ml_models_timeline.csv')\n",
    "df_ml_timeline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a1e8b-b056-430c-a31f-c537b5e1dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_ml_timeline, x='Year', y='Count', hue='Model');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c492148-6f23-45c7-b154-dd0e49f3d12d",
   "metadata": {},
   "source": [
    "Et d’un point de vue historique, on peut dire que la régression linéaire était même hégémonique jusque dans les années 1990 qui a marqué le début d’un fort dévelopemment des modèles connexionnistes (renouveau lié à la (re)découverte des algorithmes de réropropagation du gradient d’erreur dans la deuxième moitié des années 80).\n",
    "\n",
    "Régressions linéaire et logistique représentent plus de la moitié des publications. Toujours selon les données de Dörring, dans le domaine biomédical, plus de 85% des papiers rapportent la mise en œuvre d’un modèle de régression et ses variantes. C’est un modèle essentiel à connaître.\n",
    "\n",
    "Pour enfoncer le clou, ce type de modèle continue de tenir la dragée haute à des modèles plus sophistiqués en matière de sobriété. Par exemple [Varoquaux et al. (2024)](https://arxiv.org/abs/2409.14160), dans un article passant en revue les différents points que questionne la notion de sobriété en machine learning, rapportent par exemple que [Ericksson et al. (2023)](https://pmc.ncbi.nlm.nih.gov/articles/PMC10952307/) n’ont pas trouvé de différence de performance significative entre modèles de régression, deep learning, et boosted trees qui n’ont pourtant pas le même coût computationnel (loin de là). \n",
    "\n",
    "Dans ce cours nous allons nous focaliser sur des *analyses* reposant sur un modèle de régression (logistique), et non du machine learning.\n",
    "\n",
    "L’objectif dans le machine learning est de trouver les paramètres qui permettront la meilleure prédiction de la valeur d’une variable sur des données en entrée du modèle non encore observées. Cela demande la mise en œuvre d’une méthodologie particulière (créer des ensembles d’entraînement, de test, etc.) dont nous donnerons un bref aperçu à la prochaine séance. \n",
    "\n",
    "Dans une perspective statistique, notre objectif sera plutôt de proposer un modèle *explicatif* décrivant une relation d’un certain type (ici, linéaire) entre variables. Notre principal soucis sera alors de s’assurer de la *robustesse* de nos affirmations (via un processus d’inférence statistique tel que vu dans la séance 5), en évaluant à quel point cette relation linéaire est *significative*.\n",
    "\n",
    "Si on comprend bien comment les variables sont liées entre elles (un des objectifs de l’EDA) alors on pourra ensuite – si notre perspective est celle de créer in fine un modèle prédictif – choisir une méthode de ML et entrainer un modèle qui prend ces variables en entrées et sortie.\n",
    "\n",
    "Il y a deux types de régressions linéaires :\n",
    "\n",
    "* la régression linéaire simple ou univariée : une variable quantitative explicative (ou indépendantes) -> une variable quantitative expliquée (ou dépendante)\n",
    "* la régression linéaire multivariée : plusieurs variables quantitatives explicatives (ou indépendantes) -> une variable quantitative expliquée (ou dépendante\n",
    "\n",
    "Note : vous avez normalement vu dans le module de mathématiques les modèles abordés ici en détail. Nous n’y reviendrons pas, à par quelques formmules et définitions qui serviront de rappels pour poser les idées.\n",
    "\n",
    "## Régression linéaire simple\n",
    "\n",
    "### Première approche\n",
    " \n",
    "Pour détecter des patterns dans les jeux de données que nous explorons, nous avons vu l’intérêt des tables de corrélations afin de repérer des relations linéaires entre variable, avec une estimation de la force de ces relations. Une corrélation de 1 ou -1 implique une relation de proportionnalité totale entre les deux variables, les valeurs intermédiaires indiquant le degré de dépendance linéaire entre les vairables.\n",
    "\n",
    "La régression linéaire propose d’expliciter cette relation linéaire avec un modèle linéaire :\n",
    "\n",
    "$$ Var_{expliquée} = \\beta . Var_{explicative} + \\alpha $$\n",
    "\n",
    "Tout l’enjeu sera de déterminer les valeurs de *β* et *α*. \n",
    "\n",
    "Reprenons le jeu de données `tips` vu dans la séance 2 (dataviz), et affichons un résumé statistique et la table de corrélation entre les variables quantitatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a788f20-a87b-428f-9600-1cf7b59dbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df = sns.load_dataset(\"tips\")\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33245753-c84a-4801-8b28-dcd44e3cc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour faciliter la lecture, on peut arrondir la valeur des statistiques\n",
    "\n",
    "# si on veut se la péter :\n",
    "tips_df.describe().map(lambda x: round(x, 2))\n",
    "\n",
    "# si on veut être lisible :\n",
    "# round(tips_df.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637859e6-8ddd-47ac-9ad5-bd6532e0e678",
   "metadata": {},
   "source": [
    "On a le sentiment que plus le montant de l’addition est élevé, plus le pourboire sera important. La dispersion de la taille des repas étant moins importante la relation semble toujours positive, mais plus ténue en matière de distribution. \n",
    "\n",
    "#### Corrélations\n",
    "\n",
    "Voyons les corrélations linéaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5f92c-9450-47db-8d2b-29da05cd7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(tips_df[['total_bill', 'tip', 'size']].corr(), \n",
    "            cmap='coolwarm', \n",
    "            annot = True, # affiche les valeurs dans les cellules\n",
    "            annot_kws={\"size\": 12}); # taille des chiffres dans les cellulles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38861b15-5f2d-4bc2-880a-4f61dacb88de",
   "metadata": {},
   "source": [
    "La corrélation (positive) la plus forte est en effet entre le montant de l’addition et celui du pourboire : *r* > 0.5. Pour la taille du repas, la corrélation n’atteint pas 0.5. Vérifions cela graphiquement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afb969-c9cd-49b2-a569-2b976d54b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips_df).set_title('Pourboires en fonction du montant de l’addition');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1b7e4-9628-4664-979d-7c1df25c72e7",
   "metadata": {},
   "source": [
    "La relation de proportionalité (linéarité) entre les variable se distingue « à l’œil nu », même si cela ne fait naître qu’une intuition, et que des calculs sont nécessaires pour quantifier précisément cette proportionalité. On distingue aussi que la variabilité des pourboires les plus élevés est très importantes pour les additions les plus élevées. Cela peut poser des problèmes, nous y reviendrons plus tard.\n",
    "\n",
    "#### Approche dataviz\n",
    "\n",
    "Nous avions vu également comment avec Seaborn nous pouvions tracer la droite de régression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8fac6-ec72-4479-bf5b-7c730deed5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='total_bill', y='tip', data=tips_df).set_title('Droite de régression du pourboire sur le montant de l’addition');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc3848-a5ef-496c-aeff-07b5f02aaa33",
   "metadata": {},
   "source": [
    "Attention à l’interprétation !!!\n",
    "\n",
    "Même si l’on emploi la notion « d’explication » dans le vocabulaire de l’analyse statistique, cela ne vaut pas causalité. On ne peut pas interpréter notre modèle en concluant qu’une addition élevée *cause* ou provoque le versement d’un pourboire élevé. Il faut plutôt dire :\n",
    "\n",
    "* les pourboires des repas avec une addition élévée sont plus important\n",
    "* une bonne partie de la variabilité (variance) des pourboires est *expliquée* par le montant de l’addition (c’est là qu’intervient la notion d’explication)\n",
    "\n",
    "Il existe des analyses statistiques qui permettent de conclure à une relation de causalité, comme les [analyses de médiation](https://theses.hal.science/tel-03194558) par exemple. Mais elles demandent plusieurs analyses complémentaire et impliquent l’intervention d’une variable intermédiaire dont on va (schématiqueemnt) tenter de mesurer l’effet quand elle est présente ou pas. Ce n’est absolument pas le cas ici où l’on met simplement en relation deux variables.\n",
    "\n",
    "On peut caractériser (quantifier) cette relation : \n",
    "\n",
    "* quand on dit que les additions élevées sont associées à des pourboires plus importants, on peut quantifier cela avec le coefficient de corrélation *β* : les additions de 1\\\\$ plus élevées, ont des pourboires β\\\\$ plus élevés\n",
    "*  quand on dit qu’une partie de la variance des pourboires est expliquée par le montant de l’addition, on peut quantifier cette part expliquée grâce au coefficient de corrélation.\n",
    "*  *r<sup>2</sup>* est plus souvent utilisé que la simple corrélation *r*, car il rend compte de la *qualité* (explicative – en terme de variance) du modèle. **Attention, *r<sup>2</sup>* n’indique pas la *force* de l’impact du montant de l’addition sur les pourboires**. Pour se le représenter facilement, plus *r<sup>2</sup>* est petit, plus les points vont être dispersés autour de la droite de régression (car une bonne part de leur variance n’est pas expliquée ou contrôlée par notre variable explicative). Cette dispersion est *l’erreur*, la part de variance qui n’est pas expliquée par notre modèle (qui vient donc d’autres facteurs non pris en compte et que nous ingorons).\n",
    "\n",
    "Pour visualiser cela, créons artificiellement deux ensemble de données qui obéissent à une relation linéaire (équation de droite) avec les même paramètres, mais « bruité » de manière uniforme. Un jeu étant plus bruité que l’autre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e58b9c-f2d7-472c-975e-c43cbc3bb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.3\n",
    "alpha = 5\n",
    "\n",
    "x = 3 * np.random.rand(100, 1)\n",
    "\n",
    "erreur1 = np.random.randn(100, 1) * 0.8\n",
    "y1 = beta * x + alpha + erreur1\n",
    "\n",
    "erreur2 = np.random.randn(100, 1) * 0.1\n",
    "y2 = beta * x + alpha + erreur2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87f78c-fd99-4135-b125-01876caa9e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr     \n",
    "r1 = pearsonr(x, y1)[0][0]\n",
    "r2 = pearsonr(x, y2)[0][0]\n",
    "\n",
    "print(f'r1 carré = {r1**2} et r2 carré = {r2**2}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9076f4b-4fd1-4934-8e1a-ae4093f5b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "g1 = sns.regplot(x=x, y=y1, color='r')\n",
    "g1.set_ylim(2, 8) \n",
    "g1.set_title(f'r2 = {round(r1**2,2)} (faible part de la variance expliquée)')\n",
    "plt.subplot(1,2,2)\n",
    "g2 = sns.regplot(x=x, y=y2, color='b')\n",
    "g2.set_ylim(2, 8) \n",
    "g2.set_title(f'r2 = {round(r2**2,2)} (part importante de la variance expliquée')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332dfd3f-69a7-4dd8-aa85-34165c43ef56",
   "metadata": {},
   "source": [
    "On remarque naturellement que cela a un effet également sur l’intervale de confiance.\n",
    "\n",
    "D’ailleurs imaginons que l’on prenne un sous-échantillon au hasard pour évaluer notre modèle dans chaque cas, quel serait l’effet sur l’intervalle de confiance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463db006-0a57-459e-bcd2-e31c9b4a8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "idx_sample = np.random.choice(n, size=10, replace=False) # on choisit 10 index aux hasard pour constituer nos sous-échantillons\n",
    "x_sample = x[idx_sample]\n",
    "y1_sample = y1[idx_sample]\n",
    "y2_sample = y2[idx_sample]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(2,2,1)\n",
    "g1 = sns.regplot(x=x, y=y1, color='r')\n",
    "g1.set_ylim(2, 8) \n",
    "plt.subplot(2,2,2)\n",
    "g2 = sns.regplot(x=x_sample, y=y1_sample, color='r')\n",
    "g2.set_ylim(2, 8) \n",
    "plt.subplot(2,2,3)\n",
    "g3 = sns.regplot(x=x, y=y2, color='b')\n",
    "g3.set_ylim(4.5, 6.5) \n",
    "plt.subplot(2,2,4)\n",
    "g3 = sns.regplot(x=x_sample, y=y2_sample, color='b')\n",
    "g3.set_ylim(4.5, 6.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc3179-6ca4-41d9-8345-c95b727e37f3",
   "metadata": {},
   "source": [
    "Quand on veut comparer facilement les `regplot` dans un  dataframe, on peut utiliser `sns.lmplot()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999fe4c-1adf-4383-b465-456c110c004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips_df, x=\"total_bill\", y=\"tip\", hue=\"sex\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908246d5-03bc-4aa9-b3ca-3759cc4d7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips_df, x=\"total_bill\", y=\"tip\", col=\"sex\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eec69a-5a30-4fe1-b7f5-cab5a234027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips_df, x=\"total_bill\", y=\"tip\", col=\"day\", row='sex', hue='smoker');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aae572-bafc-4cc0-99e6-e900aacdcd7d",
   "metadata": {},
   "source": [
    "C’est bien beau mais comment quantifier précisément les paramètres, l’erreur, la qualité des modèles etc. ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02eaca1-4c82-4ea5-a2bf-62cbac9a9b08",
   "metadata": {},
   "source": [
    "### Modèle statistique : estimation des paramètres et bibliothèque `statsmodels`\n",
    "\n",
    "La bibliothèque de référence pour le ML est `scikit-learn`. Mais si l’on s’en tient à une approche d’exploration et d‘analyse des données, [la bibliothèque `statsmodels`](https://www.statsmodels.org/stable/index.html) est très intéressante : elle est très facile à utiliser avec une API `formula` qui reprend le format de notation `patsy` [(lien)](https://patsy.readthedocs.io/en/latest/) avec laquelle les utilisateur-ice-s de `R` [(lien)](https://www.r-project.org/) sont déjà familier-ère-s.\n",
    "\n",
    "Par exemple, pour une régression du montant des pourboires sur les montants des additions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be501b6d-043f-415a-8ab3-1e447ba77d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1228cd-3127-45c8-83d4-e5b0d0ac07cf",
   "metadata": {},
   "source": [
    "Les étapes sont globalement les étapes que l’on retrouvera à chaque fois que l’on va chercher à établir un modèle :\n",
    "\n",
    "- import des modules contenants les modèles\n",
    "- assignation des variables (expliquée et explicative-s)\n",
    "- définition du modèle (la « formule » en quelque sorte) et de la méthode d’estimation (dans le cas de la régression simple, l’estimation se fera par la méthode des moindres carrées (OLS)\n",
    "- estimation des paramètres du modèle avec une méthode généralement appelée `.fit()`\n",
    "- lecture et interprétation des résultats et évaluation de la performance du modèle, aidé par de nombreux indices statistique (intervalles de confiance, erreur standard, *r<sup>2</sup>*, indice de Fisher…) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2c6ea-0a8b-45c8-9f30-3f38574e846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af1837-bb60-413f-9cb5-236ab2a05ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= tips_df['tip'].tolist() # variable expliquée\n",
    "X = tips_df['total_bill'].tolist() # variable explicative\n",
    "X = sm.add_constant(X) # ajout du terme constant\n",
    "model = sm.OLS(Y, X) # instanciation du modèle, estimation à l’aide de la méthode des moindres carrés\n",
    "result = model.fit() # estimation des paramètres du modèle\n",
    "result.params # lecture de la valeur des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576da96-b8c1-4de8-9fa9-498ca861a3bb",
   "metadata": {},
   "source": [
    "La méthode `.summary()` nous livre les principaux indicateurs statistiques, erreur, test de significativité, etc. :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f410c-6de9-4ba3-af39-60be23e95851",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d54d9-3695-4f4c-9f53-78aaa4276346",
   "metadata": {},
   "source": [
    "* En haut à gauche on retrouve un résumé du modèle (variable, type, méthode d’estimation…) et de l’échantillon (nombre d’observation, degrés de liberté…)\n",
    "* En haut à droite sont affichés les indices statistiques qui portent sur le modèle dans sa globalité : Fisher, *r<sup>2</sup>, AIC (utile pour comparer des modèles entre eux), etc.\n",
    "* En bas on a, paramètre par paramètre, erreur standard, leur significativité (test de Student), intervalle de confiance, etc.\n",
    "\n",
    "Rappel sur l’indice de Fisher : correspond à l’hypothèse nulle « tous les paramètres sont égaux à 0 ». Plus la valeur de F est grande, plus le modèle a de chance d’être statistiquement significatif, c’est à dire qu’au moins un des paramètres est significativement différent de 0. Si la valeur de F est proche de 1, alors on ne peut pas rejeter l’hypothèse nulle. Attention, F est un indice doté de degrés de liberté, notamment liés à la taille de l’échantillon et au nombre de paramètres du modèle. Pour chaque taille d’échantillon et chaque modèle (notamment lorsque l’on considère plusieurs variables, donc plusieurs paramètres) le seuil de significativité associé à F a une valeur spécifique.\n",
    "\n",
    "Les objets liés au modèle (retourné par `.OLS()` et au résultat (retourné par `.fit()`) disposent de différents attributs et méthodes (comme `.summary()` par exemple) :\n",
    "\n",
    "* Les variables / paramètres du modèle sont accessibles via les attributs `.endog_names` (variable endogène -> variable expliquées) et `.exog_names`(variable exogènes -> variables explicatives) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a7f54-c30a-43c2-b78c-ec16bada7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.endog_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ef853-088e-4421-8600-b2fbb5eb14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.exog_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea769818-72eb-4fbc-9e3b-bb96a770acf0",
   "metadata": {},
   "source": [
    "* `statsmodels` propose également une API qui via `patsy` permet de définir les modèles de manière plus intuitive ou lisible, qui est très proche de la manière dont on procède avec `R` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0bb8c-d6a8-498d-834d-7900f9d9df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250155bf-3b5b-4c42-8fcb-aacb96850e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula = 'tip ~ total_bill', data=tips_df)\n",
    "result = model.fit()\n",
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19ebc8-633e-486c-aa2d-ccc653ac4a69",
   "metadata": {},
   "source": [
    "La présentation des paramètres est également plus lisible.\n",
    "\n",
    "* L’objet retourné par cette méthode `.ols()` (qui se distingue par le fait qu’elle est écrite en minuscule) dispose également des attributs `.endog_names` et `.exog_names` – ici aussi plus lisibles – mais aussi de l’attribut `.formula` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2087b1-6e70-47b7-a512-521eca7b68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.endog_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e5a22-9ad1-44d5-a862-1554b80f02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.exog_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989b172-0ad8-4891-92d7-a9b7486c91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c7242-4edf-4dba-af95-7bd16ce14233",
   "metadata": {},
   "source": [
    "* bien sûr on dispose également de `.summary()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd65649-734d-4183-888f-cc007ad50d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78db4fa-1df2-4ead-82aa-1e23135c3604",
   "metadata": {},
   "source": [
    "* On peut accéder directement à certains indices comme des attributs de l’objet retourné par la méthode `.fit()` (que nous avons nommé `result`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bffa2c-6315-48f8-b056-9e526d14aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500f9e9-d253-4267-8d8b-135ca1a46a6e",
   "metadata": {},
   "source": [
    "* l’objet retourné par la méthode `.fit()` (result/fitted) dispose d’une méthode `.predict()` qui permet de générer les valeurs prédites par le modèle. On l’utilise souvent en lui donnant pour argument les valeurs réelles des variables indépendantes afin de comparer valeurs prédites / valeurs observées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5721f-35af-45c2-aeb9-5be240f0a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.predict(tips_df['total_bill']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2a47a-9016-4b39-8e09-b162d39d6cc6",
   "metadata": {},
   "source": [
    "Attention, si on n’utilise pas le formalisme `patsy` pour notre modèle (méthode `.OLS()` de l’API de base, et non `.ols()`), il faut ajouter une colonne pour l’intercept avec la méthode `.add_constant()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ddd9b6-4e62-4cf2-83f6-cdf64493c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sm.OLS(Y, X) # X et Y définie plus haut\n",
    "result2 = model.fit()\n",
    "predicted_tips = result2.predict(sm.add_constant(np.asarray(tips_df['total_bill'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e6480-0c61-4a12-9627-1745d884178e",
   "metadata": {},
   "source": [
    "Si l’on veut prédire une valeur unique (par exemple quel pourboire pour une addition de 50$ ?), le modèle décrit avec le formalisme `patsy` attend un DataFrame ou une Series :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6b7ec-ec83-47bc-ba44-ea293203e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.predict(pd.DataFrame({'total_bill': [50.0]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9087c5-5544-47fb-9fa2-960d4f8d7347",
   "metadata": {},
   "source": [
    "On peut utiliser ces valeurs prédites pour tracer la droite de régression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715ebc9-ffe9-45cd-a2a3-dc1024993728",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.scatterplot(x='total_bill', y='tip', data=tips_df, ax=ax)\n",
    "sns.lineplot(x=tips_df['total_bill'], y=predicted_tips, color='r', ax=ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee6ade-a705-476d-8eb0-ecbad1f03200",
   "metadata": {},
   "source": [
    "### Variables catégorielles (ou qualitatives)\n",
    "\n",
    "La régression est un modèle qui originellement était destiné à expliquer la vairance d’une variable quantitative par une autre variable qualitative. Pour les variables catégorielle on utilise un autre modèle appelé ANOVA (analyse de la variance). Mais on peut tout de même utiliser la régression simple dans le cas d’une variable catégorielle particulière : si elle est binaire. Dans notre exemple il pourrait s’agir de la variable sex (male/female), time (lunch/dinner) ou encore smoker/non-smoker. On peut simplement remplacer ces variables par une valeur numérique, en les codant de manière binaire : 0 pour male, et 1 pour female par exemple. \n",
    "\n",
    "Dans ce cas on va indiquer à `statsmodels` qu ’on veut utiliser une variable catégorielle qu’on va encoder :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a22b0f-6c45-4fe6-9177-57b9cd11a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat = smf.ols(formula='tip ~ C(sex)', data=tips_df)\n",
    "model_cat.fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b857033-a7c8-4d7b-9b56-b228a79924fd",
   "metadata": {},
   "source": [
    "L’intercept est la valeur prédite pour le groupe par défaut (ici le groupe `male`), et *β* de combien évolue la variable expliquée quand on « passe » à l’autre groupe (`female` ici)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593295e-a477-434e-925f-841f00824a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.scatterplot(x='sex', y='tip', data=tips_df, ax=ax)\n",
    "sns.lineplot(x=tips_df['sex'], y=model_cat.fit().predict(tips_df['sex']), color='r', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f8b9e-a9fd-4c0f-b1b7-ea824fd83cf0",
   "metadata": {},
   "source": [
    "Voyons si on peut faire confiance à ce modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ef4e3-2e95-4f10-8981-6362c439595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa420c3-5c91-48ad-bdc2-c752d4622b31",
   "metadata": {},
   "source": [
    "Quelles sont vos conclusions à la lecture de ce tableau ?\n",
    "\n",
    "<votre réponse ici>\n",
    "\n",
    "Si l’on dispose de plus de catégories (comme les jours de la semaine dans notre exemple), le codage est plus compliqué et sera décomposé en plusieurs variables (une de moins que le nombre de catégories), nous y reviendrons dans la section ci-dessous sur la régression multivariée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0460d5-3c68-4c1c-9dc4-350533defaa0",
   "metadata": {},
   "source": [
    "### Analyse des résidus\n",
    "\n",
    "La régression est un outil puissant, mais on ne peut pas l’utiliser à tort et à travers. Il y a des conditions précises de validité d’emploi de ce type de modèle :\n",
    "\n",
    "* échantillonage aléatoire\n",
    "* échantillonage indépendant (rappel : un échantillonage avec remplacement est acceptable si n < 10% de la population)\n",
    "* homoscédasticité (distribution normale des résidus, et variance égale des résidus)\n",
    "\n",
    "Si les deux premières conditions sont vérifiables en évaluant la méthode retenu pour l’échantillonage, vérifier l’homoscédasticité demande des analyses spécifiques. \n",
    "\n",
    "Une première étape est une inspection visuelle. Pour cela :\n",
    "\n",
    "- calculer les valeurs prédites par le modèle\n",
    "- retrancher les valeurs observées : cela nous donne les résidus (erreur)\n",
    "- afficher un histogramme des résidus : la moyenne devrait être autour de 0 et la distribution normale (ou faire un test de normalité)\n",
    "- enfin afficher un scatterplot entre les valeurs prédites et les résidus. Vérifier qu’aucun pattern n’apparaît\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842745bd-4346-45b8-937a-b3a1b41a2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tips = result.predict(tips_df['total_bill'])\n",
    "residuals = tips_df['tip'] - predicted_tips \n",
    "sns.histplot(residuals, kde=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f5615-0a15-4c66-8d72-e7a185f1cc1a",
   "metadata": {},
   "source": [
    "En réalité, la classe `Results()` de `statsmodels` possède un attribut `.resid` qui permet d’accéder directement aux résidus : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3639620-21a1-46bb-8e48-a38344ff6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(result.resid, kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a078c-f19e-484f-bff4-21b7730edd8f",
   "metadata": {},
   "source": [
    "#### QQ-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7700111b-4649-42f2-a09c-04cc3105de2c",
   "metadata": {},
   "source": [
    "Il existe une méthode pour apprécier graphiquement très rapidemnet si une distribution est normale : les QQ-plot\n",
    "\n",
    "1. on calcule les quantiles pour nos données, on note les valeurs\n",
    "2. on regarde où tombent ces valeurs/quantiles sur une distribution normale\n",
    "3. on trace un scatterplot valeurs sur la normale (théorique) / valeurs sur nos données (réelles)\n",
    "4. si nos données // à une normale, on devrait voir une droite. Si non, c’est qu’il y a une « distortion » dans la distribution // à une normale\n",
    "\n",
    "[Une vidéo de Statquest](https://www.youtube.com/watch?v=okjYjClSjOg) où la procédure est expliquée pas à pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948968e3-3522-4fc7-a6bb-871a41149472",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals, line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd56b97-578a-4899-9f96-640a94896147",
   "metadata": {},
   "source": [
    "#### Résidus vs. valeurs prédites\n",
    "\n",
    "Plutôt que dessiner un simple `scatterplot()`, on peut avec un `regplot()` avoir un aperçu des tendances :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8c562-8d52-4d8a-b96f-82ce3b70c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.regplot(x=predicted_tips, y=residuals)\n",
    "g.set_xlabel('predicted_tips')\n",
    "g.set_ylabel('residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e345e9-6327-4c5c-9a8d-fcac1092f02a",
   "metadata": {},
   "source": [
    "#### Interprétation des résidus ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87073bd2-042e-43cf-bfd9-63b912a5ab28",
   "metadata": {},
   "source": [
    "Dans nootre exemple, si la distribution semble parfaitement normale (avec peut-être une légère dissymétrie), on voit clairement apparaître un pattern dans le diagramme residus vs. predicted/fitted : la variance augmente légèrement pour les prédictions des pourboires les plus élevés (ce que l’on suspectait déjà par l’observation des données brutes). Il est possible qu’une autre variable ou un phénomène particulier intervienne dans le processus à l’origine des hauts pourboires.\n",
    "\n",
    "On peut observer toute sortes de patterns, mais en général ce qui nous alerte est une augmentation (ou une diminution) de la variance. C’est souvent le signe qu’une autre variable intervient.\n",
    "\n",
    "Que faire dans ce cas ? On reste dans une optique d’exploration et de préparation des données : \n",
    "\n",
    "* rechercher si d’autres variables peuvent intervenir\n",
    "* voir si une transformation de la variable (`log()`, etc.) améliore les choses\n",
    "* opter pour un autre modèle (peut être que la relation entre variable n’est pas linéaire).\n",
    "\n",
    "Note : se méfier de la temporalité (phénomène d’inflation avec le temps sont très courants, ou périodicité), on en revient à une bonne compréhension des phénomènes, observation, méthode d’acquisition, connaissance métier… afin de bien prendre en compte tous les facteurs qui peuvent avoir une influence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be875094-4aac-43b6-9fdf-69fff1975689",
   "metadata": {},
   "source": [
    "Ensuite, il existe des tests d’hétéroscédasticité : les tests de Breusch-Pagan et de White, accessible respectivement avec `het_breuschpagan` et `het_white` dans le module `diagnostics` :\n",
    "\n",
    "Breusch-Pagan : régression des carrés des résidus sur les variables indépendantes. Hypothèse nulle : pas d’hétéroscédasticité. Si le test est significatif, alors cela suggère que les conditions d’homoscédasticité ne sont pas remplies.\n",
    "\n",
    "White : teste une relation entre les carrés des résidus et les variables indépendantes (sans hypothèse particulière sur le type de relations à l’inverse de Breusch-Pagan). Comme précédemment un test significatif suggère que les conditions d’homoscédasticité ne sont pas remplies.\n",
    "\n",
    "Ces tests appartiennent au module `diagnostic`.\n",
    "\n",
    "Test de Breusch-Pagan (il faut ajouter un terme constant aux variables indépendantes testées avec `.add_constant()`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1f5b1-c210-431e-b1c2-b0576d4d9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.diagnostic as smd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91594f87-ee84-4bc7-bd18-c4d23f2f9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_test_results = smd.het_breuschpagan(resid=result.resid, exog_het=sm.add_constant(np.asarray(tips_df['total_bill'])))\n",
    "bp_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8df89-848f-4357-a7aa-df18ca2678cd",
   "metadata": {},
   "source": [
    "Tous les paramètres de la régression sont (très) significatifs : les conditions d’homoscédasticité ne sont pas remplies.\n",
    "\n",
    "Test de White (qui ne fait pas d’hypothèse sur la forme de la relation fonctionnelle entre les résidus et la variable indépnedante) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e11654-b98a-467f-9c45-bbff7475b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_test_results = smd.het_white(resid=result.resid, exog=sm.add_constant(np.asarray(tips_df['total_bill'])))\n",
    "w_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b2c1a-ea5e-441b-b99e-58d2c10a9d14",
   "metadata": {},
   "source": [
    "De même pour le test de White."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d5a33-3fac-4788-93b9-08e84b507e6f",
   "metadata": {},
   "source": [
    "## Régression multivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b2019-2e42-4aeb-941f-b0aee64189bf",
   "metadata": {},
   "source": [
    "### Modèle\n",
    "\n",
    "La régression simple est une relation linéaire à une seule dimension (une seule variable indépendante). On peut vouloir considérer simultanément plusieurs variables, chacune expliquant une part – plus ou moins importante – de la variance de la variable dépendante. La régression est alors une combinaison linéaire : \n",
    "\n",
    "$$ Var_{expliquée} = \\beta_{1} . Var_{explicative_1} + \\beta_{2} . Var_{explicative_2} + … +\\beta_{n} . Var_{explicative_n} + \\alpha $$\n",
    "\n",
    "Pour estimer la part de chaque variable explicative, on va estimer un paramètre, plus un terme constant (*intercept*).\n",
    "La spécification du modèle est presque aussi simple que pour la régression simple (oui, on garde les mêmes données, même si on a vu que l’homoscédasticité c’était pas trop ça, YOLO!, c’est juste dans un but d’illustration) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8314e0e-54b2-4db3-a426-0aacd8182426",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = smf.ols(formula='tip ~ total_bill + size', data=tips_df)\n",
    "multi_result = multi_model.fit()\n",
    "multi_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307242dd-938f-401b-aee4-234593703a7b",
   "metadata": {},
   "source": [
    "L’interprétation est par contre est un peu plus complexe. Par exemple le paramètre attaché à `total_bill` signifie que pour une variation de 1\\\\$ sur l’addition, le pourboire varira de 0.092713\\\\$, mais comme il y a d’autre paramètres qui peuvent expliquer des variations aussi, c’est en précisant que *les autres variables sont maintenues égales par ailleurs* (=constantes).\n",
    "\n",
    "### Qualité du modèle\n",
    "\n",
    "Par ailleurs, le fait qu’il y ait plusieurs variables, comment estimer la qualité du modèle comme on le faisait pour la régression simple avec *r<sup>2</sup>* ?\n",
    "\n",
    "En effet *r* rend compte de la relation linéaire entre deux variables. Quel indice pourrait jouer le même rôle avec plus de deux variables ?\n",
    "\n",
    "Revenons aux résidus. Si l’on considère la qualité d’une modèle c’est quel pourcentage de variance il est capable d’expliquer, en minimisant la part des erreurs (résidus), un bon indice serait juste le ratio résidus sur moyenne (en fait les sommes de carrés). Pourquoi la moyenne ? Car en général le modèle le plus basique que l’on puisse créé est un modèle qui prédit la moyenne. On obtiendrait ainsi un indice de qualité du modèle en le comparant à un modèle de référence de base : la moyenne. Le modèle avec la meilleure qualité serait un modèle où l’erreur serait réduite à 0. Par analogie avec *r<sup>2</sup>*, on peut fixer par convention que ce modèle le plus qualitatif obtienne un score de 1. Une formule qui correspond à cette situation serait :\n",
    "\n",
    "$$ 1 - \\frac{SC_{residus}}{SC_{moyen}} = R^{2}$$\n",
    "\n",
    "On appelle cet indice *R<sup>2</sup>* par analogie, mais ce n’est pas un carré : il peut être négatif si la somme des carrés des résidus est plus grande que la somme des carrés moyens !\n",
    "\n",
    "Ainsi :\n",
    "\n",
    "* *R<sup>2</sup>* = 1 : toute la variance est expliquée par les variables indépendantes\n",
    "* *R<sup>2</sup>* > 0 : le modèle est meilleur que la prédiction par la moyenne\n",
    "* *R<sup>2</sup>* = 0 : le modèle est équivalent à prédire la moyenne\n",
    "* *R<sup>2</sup>* < 0 : un modèle linéaire est si peu adapté aux données qu’un modèle de prédiction par la moyenne est meilleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec59a44-f045-4d7b-920e-bf8d2e77359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_result.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c9138-793e-468e-bcbc-442833f62c96",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Une régression multiple, multidimentionnelle, est difficile à représenter graphiquement. De la même manière qu’un coefficient de régression multivariée s’interprête en maintenant les autres paramètres constants, il est plus aisé de créer des représentations grahiques pour chaque paramètre en maintenant les autres constants (affichage en grille). `statsmodels` possède des méthodes pour tracer des graphiques (module `graphics`) dont la méthode `.plot_partregress_grid()` qui nous intéresse ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce08327-e38e-4d1d-b430-a8e061eedb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "fig = sm.graphics.plot_partregress_grid(multi_result, fig=fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e48eda-8c90-4f4d-a100-f3e204d18a7b",
   "metadata": {},
   "source": [
    "Un tracé de régression partielle est une forme d’analyse des résidus.\n",
    "\n",
    "On veut voir l’effet d’une variable sur une autre, en éliminant l’effet de toutes les autes variables.\n",
    "Les autres variables peuvent avoir un effet sur la variable que l’on cherche à expliquer, mais aussi sur la variable explicative que l’on considère en particulier.\n",
    "Dans notre exemple, `size` peut avoir un effet sur `tip`, mais aussi sur `total_bill`. Donc si on veut isoler l’effet exclusif de `total_bill` sur `tip`, il faut trouver un moyen d’éliminer l’influence de `size`.\n",
    "\n",
    "![Diagramme de Venn expliquant les parts expliquées par les régressions](./images/Venn_regression.png)\n",
    "\n",
    "C’est là qu’interviennent les résidus : si on cherche à isolé la part de `tip` expliquée exclusivement par `total_bill`, il faut supprimer la part de `total_bill` expliquée par `size`, et la part de `tip` expliquée par `size`. Or c’est exactement ce que sont les résidus :\n",
    "\n",
    "- le résidu de la régression de `tip` sur `size` est la part de la variance de `tip` non expliquée par `size`\n",
    "\n",
    "- le résidu de la régression de `total_bill` sur `size` est la part de la variance de `total_bill` non expliquée par `size`\n",
    "\n",
    "Donc la régression du résidu de (`tip` sur `size`) sur le résidu de (`total_bill` sur `size`) est la part de `tip` expliquée exclusivement par `total_bill`\n",
    "\n",
    "Donc pour tracer les régression partielles, pour chaque variable :\n",
    "\n",
    "- 1. on réalise une régression en excluant la variable indépendante considérée - par exemple `total_bill` (c’est à dire on crée un modèle expliquant `tip` par toutes les autes variables que `total_bill` – ici `size`, mais on pourrait avoir un modèle plus complexe avec plus de variables). On obtient les résidus `e(tip|X)` de cette régression.\n",
    "\n",
    "- 2. on réalise ensuite une régression de la variable indépendante considérée (`total_bill` dans notre exemple) et les auters varaibles, et on obtient des résidus `e(total_bill|X)`.\n",
    "\n",
    "- 3. on trace enfin un scatterplot des résidus (dans notre exemple `e(tip|X)` sur `e(total_bill|X)`) et la droite de régression associée\n",
    "    - l’axe des ordonnées (y) indique les valeurs des résidus du modèle contenant toutes les variables sauf la variable d’intérêt (`total_bill`) : c’est donc toutes les erreurs qui restent quand on a pris en compte les autres variables que `total_bill`\n",
    "    - l’axe des abscisses (x) indique les valeurs des résidus du modèle expliquant la variable d’intérêt (`total_bill`) par toutes les autres : la variance que l’on observe n’est pas due aux autres variables\n",
    "\n",
    "- pour la droite de régression résultante, l’*intercept* vaut forcément zéro, et la pente de la droite est la « force » de l’explication de la variance de `tip` par `total_bill`, indépendemment des autres variables. Ces graphes permettent en outre de voir quels points (qui ne représentent pas les données observées, mais les interpolations sur les erreurs) posent problème avec les plus grandes erreurs :\n",
    "    - sur l’axe x : les points les plus éloignés de 0 (en positif ou négatif) sont les points pour lesquels la variable d’intérêt (`total_bill`) a une valeur inexpliquée par les autres variables (avec la plus grande erreur)\n",
    "    - sur l’axe y : les points les plus éloignés de 0 (en positif ou négatif) sont les points pour lesquels le modèle privé de `total_bill` explique le moins la valeur du point (avec la plus grande erreur)\n",
    "    - donc ce sont les points qui « jouent » le plus dans l’explication de `tip` par `total_bill`\n",
    "  \n",
    "En matière d’interprétation de ces graphes, les variables qui contribuent le plus à expliquer la variance sont ceux pour lesquels la pente la plus forte est observée. Chaque tracé est centré sur 0 selon les mêmes unités, les autres variables étant fixées (à leurs valeurs moyennes). \n",
    "\n",
    "Il est important de retenir que les points ne représentent pas les données observées (pour s’en rendre compte : la variable `size` ne devrait avoir que des valeurs entières). Pour mieux identifier les points, on peut utiliser le flag `obs_labels` de la méthode `.plot_partregress()` qui trace un graphe spécifique (pas en *grid*), et pour laquelle il faut indiquer explicitement la variable dépendante (ou endogène), la variable indépendante d’intérêt, et les autres variables indépendantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2b5e3-b7aa-439f-8423-ead2d9534065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.plot_partregress(endog='tip', exog_i='total_bill',\n",
    "                              exog_others=['size'],\n",
    "                              data=tips_df, obs_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd09d5f-c598-4b3d-9591-8ff574d6eda7",
   "metadata": {},
   "source": [
    "### Variables catégorielles\n",
    "\n",
    "Nous avions vu dans la section précédente que lorsque la régression simple ne permettait pas de gérer les encodages de variables catégorielles qui avaient plus de deux catégories (binaires). Dans ces cas, la régression multivariée va nous aider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36221640-9c8c-44ca-8004-3005ed4e6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = smf.ols(formula='tip ~ C(day)', data=tips_df)\n",
    "multi_result = multi_model.fit()\n",
    "multi_result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4126d-de45-49e4-b82c-dafafa4dd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df['day'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1b20c-b11c-4659-a6a7-0987fe2f1aa6",
   "metadata": {},
   "source": [
    "Une catégorie est associée à l’*intercept*, c’est la base à partir de laquelle les coefficients vont être interprétés : \n",
    "\n",
    "* le modèle prédit des pourboires de 2,77\\\\$ le jeudi (la moyenne de ce jour), \n",
    "* une baisse de -0,04\\\\$ le vendredi, \n",
    "* une hausse (relativement au jeudi) de 0,22\\\\$ le samedi \n",
    "* et une hausse (toujours relativement au jeudi) de 0,48\\\\$ le dimanche\n",
    "\n",
    "Si on veut par exemple que chaque coefficient corresponde plutôt aux valeurs moyennes de ces catégories, il faut supprimer l’intercept du modèle. Dans ce cas on peut écrire la formule ainsi, en rajoutant simplement un `-1` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00eb5b-0934-4e2c-94da-f65273cc0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = smf.ols(formula='tip ~ C(day) -1', data=tips_df)\n",
    "multi_result = multi_model.fit()\n",
    "multi_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edff00-733a-4d83-87a4-563065f8373c",
   "metadata": {},
   "source": [
    "## Danger de la multicolinéarité\n",
    "\n",
    "Les dernières sections précédentes (indépendance des variables et résidus, encodage des variables catégorielles) devrait attirer votre attention sur un fait : les variables peuvent s’influencer les unes les autres. Soit complètement (les variables ont un rapport de proportionnalités entre elles) ou juste une covariance. Les effets sur une régression peuvent être dévasgtateurs.\n",
    "\n",
    "Il est toujours bon d’étudier la matrice de corrélations pour bien s’assurer de l’indépendance des variables avant des les choisirs conjointement dans un modèle.\n",
    "\n",
    "Pour rappel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdda50c-38d2-4c52-a901-49175953d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(tips_df[['total_bill', 'tip', 'size']].corr(), \n",
    "            cmap='coolwarm', \n",
    "            annot = True, # affiche les valeurs dans les cellules\n",
    "            annot_kws={\"size\": 12}); # taille des chiffres dans les cellulles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e7bac-41b3-4803-9d9a-1db7f77b3879",
   "metadata": {},
   "source": [
    "On voit que la variable `size` et la variable `total_bill` sont corrélées : il n’est peut-être pas judicieux de les faire intervenir conjointement dans un modèle de régression. On ne peut pas faire varier la taille du repas sans faire varier l’addition, naturellement…\n",
    "\n",
    "Pour voir les effet négatif de la colinéarité, construisons une variable complètement colinéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec466d-a16e-4f44-8861-e39aade2d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df['var_col'] = 3 * tips_df['size'] - 0.5 * tips_df['total_bill']\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b45fe8-5a44-46f2-9c17-3c2a57a478ad",
   "metadata": {},
   "source": [
    "Faisont intervenir cette variable dans un modèle avec `total_bill` et `size` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef37cee-e8ad-4fe9-a622-ab71b005d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_model = smf.ols(formula='tip ~ total_bill + size + var_col', data=tips_df)\n",
    "col_result = col_model.fit()\n",
    "col_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ce7f4-a8f5-490b-b76d-48b16a683604",
   "metadata": {},
   "source": [
    "Les coefficients n’ont plus rien à voir !\n",
    "Voyons voir les autres indicateurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473fd9fd-d0a5-4a03-b0d5-1df37a02966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1bfbb6-407c-4f74-9a3e-a9d0f9e65793",
   "metadata": {},
   "source": [
    "À première vue les indices sont pas mal : un indice de Fisher qui crève le plafond, les coefficients pris individuellement sont significatifs, mais il est vrai que la nouvelle variable est un peu limite (*p*= 0.041). Mais `statsmodels` nous envoie un petit avertissement (cf. note 2)…\n",
    "\n",
    "Amusons nous à altérer légèrement une des variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c7e285-8696-47e4-aa77-4b0eab5222cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.loc[0, 'total_bill'] = tips_df.loc[0, 'total_bill'] * 1.01\n",
    "col_model = smf.ols(formula='tip ~ total_bill + size + var_col', data=tips_df)\n",
    "col_result = col_model.fit()\n",
    "col_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a51c49-0c2a-4c43-b648-58f0849d4c72",
   "metadata": {},
   "source": [
    "L’estimation des coefficients est totalement instable !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048f2cd-c85c-446b-8d18-15ca05aa23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46750cdb-635b-442c-a082-0ae87b6af2d4",
   "metadata": {},
   "source": [
    "Plus aucun coefficient n’est significatif ! Bien que l’indice de Fisher reste élevé et le *R<sup>2</sup> > 0…\n",
    "\n",
    "Et si on ajoute un terme aléatoire pour casser un peu la colinéarité (forte, mais pas complète) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5c01f-47f6-4f75-9857-727dcf8e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df['total_bill'] = tips_df['total_bill'] + np.random.rand(tips_df.shape[0])\n",
    "col_model = smf.ols(formula='tip ~ total_bill + size + var_col', data=tips_df)\n",
    "col_result = col_model.fit()\n",
    "col_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f75dd9-2ea0-43a0-b3dc-f57f9c161e23",
   "metadata": {},
   "source": [
    "Alterons encore cette colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18363469-e54a-48c9-ac61-c7d9d08c464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.loc[0, 'total_bill'] = tips_df.loc[0, 'total_bill'] * 1.2\n",
    "col_model = smf.ols(formula='tip ~ total_bill + size + var_col', data=tips_df)\n",
    "col_result = col_model.fit()\n",
    "col_result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc233d-6863-41de-bdc4-17230026d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c0a0d-85d4-4339-879f-8a216515f72d",
   "metadata": {},
   "source": [
    "Les problèmes continuent, même si la colinéarité n’est pas absolue.\n",
    "\n",
    "Comment détecter la colinéarité ? \n",
    "\n",
    "`statsmodels` dispose d’une fonction `variance_inflation_¤actor()`, ou « *vif* » qui permet de quantifier la colinéarité (plus le *vif* est élevé, et plus le risque de colinéarité l’est aussi). Il est obtenu à partir de l’inverse du *R<sup>2</sup> de la régression d’une variable contre toutes les autres (plus *R<sup>2</sup> -> 1 et plus le *vif* tend vers l’infini)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407897a2-c92f-48d6-98f8-c909411e6d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea28abf-a08f-4d70-8bba-c277a5ad01ca",
   "metadata": {},
   "source": [
    "Pour être utilisée, cette fonction doit recevoir des données qui ont été standardisées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ecc26-92eb-4489-9d0f-230416765b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['size','tip','total_bill', '] # on ne prend que les variables numériques\n",
    "tips_std = pd.DataFrame()\n",
    "\n",
    "for c in columns:\n",
    "    m = tips_df[c].mean()\n",
    "    sd = tips_df[c].std()\n",
    "    tips_std[c] = tips_df[c].apply(lambda x: (x-m)/sd)\n",
    "\n",
    "tips_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0660dd6-78a0-4227-8709-0e0689cbc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(tips_std, 0) # 0 = index of the column considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22046949-f793-4cb5-b52b-469ab4861109",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(tips_std, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4ef2f-59cd-488b-822c-50a4e077b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(tips_std, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff905aad-e61c-4e6c-a31c-f1106d2c9890",
   "metadata": {},
   "source": [
    "Si on rajoute `var_col` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb651579-058c-4d1f-8dbb-e35266fb9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['size','tip','total_bill', 'var_col'] # on ne prend que les variables numériques\n",
    "tips_std = pd.DataFrame()\n",
    "\n",
    "for c in columns:\n",
    "    m = tips_df[c].mean()\n",
    "    sd = tips_df[c].std()\n",
    "    tips_std[c] = tips_df[c].apply(lambda x: (x-m)/sd)\n",
    "\n",
    "tips_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd942d8-a34c-4ebb-a41b-217b73e0690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(tips_std, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8b900-395e-4d63-a8e0-09926e51949a",
   "metadata": {},
   "source": [
    "Question : comment on interpréte la valeur du *vif* ? Ou plus précisément : à partir de quelle valeur on commence à se poser des questions ? \n",
    "\n",
    "Il semble qu’une valeur de 10 et au-delà doit nous alerter. Mais il n’y a aucune justification théorique (expérience…) : bon sens, connaissance métier, tests (itérations) doivent nous guider…\n",
    "\n",
    "## Résumé : workflow\n",
    "\n",
    "* 1. Problème – Récupération de données\n",
    "* 2. Exploration de base des données pour les comprendre (statistique, dataviz, nettoyage, etc.)\n",
    "* 3. Hypothèses sur relation linéaire entre des données\n",
    "* 4. Modèle de régression\n",
    "* 5. Estimation des coefficient\n",
    "* 6. Diagnostic du modèle\n",
    "    * analyse des résidus\n",
    "    * QQ-plot\n",
    "    * régression partielles\n",
    "    * vif (multicolinéarité)\n",
    "* 7. Résoudre les problèmes (retour en 4.)\n",
    "\n",
    "Questions pour diagnostic :\n",
    "* qualité du modèle ? -> R<sup>2</sup>\n",
    "* significativité du modèle ? -> F-test/p-value \n",
    "* confiance dans les coefficients ? -> t-tests/p-values\n",
    "* l’inférence (test d’hypothèse) est ok ? -> analyse résidus\n",
    "* multicolinéarité ? -> vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c311712-5e4e-4e58-979b-8244ad6f0a56",
   "metadata": {},
   "source": [
    "## Exercices avec un autre dataset : `mpg`\n",
    "\n",
    "Chargez un autre dataset de `seaborn` : `mpg`. Explorez-le rapidement, et proposez un modèle de régression de la puissance des voitures, ou de leur poids, n’oubliez pas de vérifier les problèmes potentiels (homoscédasticité, colinéarité, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3eb8c7-451f-4d3d-886b-6287fd414f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset(\"mpg\")\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769a38d-d2b3-4617-b07f-e08cb81e954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code / analysis here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a6973-0566-4b18-a733-d9763a93f426",
   "metadata": {},
   "source": [
    "Pour vous entraîner, `statsmodels` propose aussi des données exemples.\n",
    "\n",
    "Voir [la liste]((https://www.statsmodels.org/dev/datasets/index.html) avec descriptions et liens, section « available dataset ».\n",
    "\n",
    "Voilà une liste rapide :\n",
    "\n",
    "```\n",
    "anes96             American National Election Survey 1996\n",
    "cancer             Breast Cancer Data\n",
    "ccard              Bill Greene's credit scoring data.\n",
    "china_smoking      Smoking and lung cancer in eight cities in China.\n",
    "co2                Mauna Loa Weekly Atmospheric CO2 Data\n",
    "committee          First 100 days of the US House of Representatives 1995\n",
    "copper             World Copper Market 1951-1975 Dataset\n",
    "cpunish            US Capital Punishment dataset.\n",
    "danish_data        Danish Money Demand Data\n",
    "elnino             El Nino - Sea Surface Temperatures\n",
    "engel              Engel (1857) food expenditure data\n",
    "fair               Affairs dataset\n",
    "fertility          World Bank Fertility Data\n",
    "grunfeld           Grunfeld (1950) Investment Data\n",
    "heart              Transplant Survival Data\n",
    "interest_inflation (West) German interest and inflation rate 1972-1998\n",
    "longley            Longley dataset\n",
    "macrodata          United States Macroeconomic data\n",
    "modechoice         Travel Mode Choice\n",
    "nile               Nile River flows at Ashwan 1871-1970\n",
    "randhie            RAND Health Insurance Experiment Data\n",
    "scotland           Taxation Powers Vote for the Scottish Parliament 1997\n",
    "spector            Spector and Mazzeo (1980) - Program Effectiveness Data\n",
    "stackloss          Stack loss data\n",
    "star98             Star98 Educational Dataset\n",
    "statecrime         Statewide Crime Data 2009\n",
    "strikes            U.S. Strike Duration Data\n",
    "sunspots           Yearly sunspots data 1700-2008\n",
    "```\n",
    "[Rowan Nichols](https://github.com/rowannicholls) propose [un petit script](https://rowannicholls.github.io/python/data/statsmodels_datasets.html) pour lister les datasets disponibles dans `statsmodels`.\n",
    "\n",
    "Explorez sans réserve !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
